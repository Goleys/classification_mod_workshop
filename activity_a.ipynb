{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc444369",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "# OpenVINO Implementation Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e81440",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This exercise purpose is oriented towards showing you a demonstration on how OpenVINO works. It is a modifed version of the Classification Tutorial made by Intel. You can find it under the OpenVINO sample in the DevCloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bdb17a",
   "metadata": {},
   "source": [
    "# Steps to cover:\n",
    "\n",
    "## A. Importing Main Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f569efb",
   "metadata": {},
   "source": [
    "## B. Creating useful functions  \n",
    "#### 1. loadInputImage\n",
    "#### 2. resizeInputImage\n",
    "#### 3. showImage\n",
    "#### 4. processAndDisplayResults\n",
    "#### 5. inferImage\n",
    "#### 6. batchLoadInputImages\n",
    "#### 7. batchProcessAndDisplayResults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398e2d9",
   "metadata": {},
   "source": [
    "## C. Setting up OpenVINO \n",
    "#### I.     Getting the pre-traine model\n",
    "#### II.    Using the Model Optimizer\n",
    "#### III.    Configuring OpenVINO parameters\n",
    "#### IV.     Creating the inference engine instance\n",
    "#### V.     Creating IENetwork & loading the model in it\n",
    "#### VI.   Checking layer compatibility\n",
    "#### VII. Loading the model into the plugin\n",
    "#### VIII.     Loading labels\n",
    "#### IX.     Preparing the Inputs\n",
    "#### X. Running the Inference\n",
    "#### XI.     Processing and Displaying Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b23c36",
   "metadata": {},
   "source": [
    "## D. Additional Info\n",
    "#### a. Loading a different image\n",
    "#### b. Loading an image from the internet\n",
    "#### c. Using multiple images\n",
    "#### d. Running multiple images\n",
    "#### e. Processing & displaying multiple images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f999b5",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise time\n",
    "## 01. Load and Process 10 AI generated images\n",
    "## 10. Change the display format\n",
    "## 11. Change the following"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6df14d",
   "metadata": {},
   "source": [
    "## A. Importing Main Libraries \n",
    "Before we start coding, we will export the libraries necessary for the model implementaton to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f23194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time \n",
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IECore\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0957247",
   "metadata": {},
   "source": [
    "## B. Creating useful functions  \n",
    "Before we go into using setting up and running our model, we'll create some functions that will help us our format everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d74505d",
   "metadata": {},
   "source": [
    "### 1.      loadInputImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadInputImage(input_path):\n",
    "    # globals to store input width and height\n",
    "    global input_w, input_h\n",
    "\n",
    "    # use OpenCV to load the input image\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "\n",
    "    # store input width and height\n",
    "    input_w = cap.get(3)\n",
    "    input_h = cap.get(4)\n",
    "    print(\"Loaded input image [\",input_path,\"]\",\"\\n\",\n",
    "          \"resolution=\", input_w,\"w x \", input_h, \"h\",)\n",
    "\n",
    "    # load the input image\n",
    "    ret, image = cap.read()\n",
    "    del cap\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8960c5a6",
   "metadata": {},
   "source": [
    "### 2.      resizeInputImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeInputImage(image):\n",
    "    # resize image dimensions form image to model's input w x h\n",
    "    in_frame = cv2.resize(image, (w, h))\n",
    "    # Change data layout from HWC to CHW\n",
    "    in_frame = in_frame.transpose((2, 0, 1))\n",
    "    # reshape to input dimensions\n",
    "    in_frame = in_frame.reshape((n, c, h, w))\n",
    "    print(f\"Resized input image from {image.shape[:-1]} to {(h, w)}\")\n",
    "    return in_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03af27f",
   "metadata": {},
   "source": [
    "### 3.      showImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4999e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(image_name,orig_input_image):\n",
    "        # display image\n",
    "    print(\"↑ RESULTS FOR THE\", image_name, \"CAN BE FINDED AT THE TOP ↑\")\n",
    "    plt.figure()\n",
    "    plt.axis(\"off\")\n",
    "    im_to_show = cv2.cvtColor(orig_input_image, cv2.COLOR_BGR2RGB)\n",
    "    # show input image\n",
    "    plt.imshow(im_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51602a88",
   "metadata": {},
   "source": [
    "### 4.      processAndDisplayResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54309f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAndDisplayResults(probs, orig_input_image, orig_input_path, image_name):\n",
    "    \n",
    "    # report top n results for image\n",
    "    print(\"Top \", report_top_n, \" results for image\", orig_input_path, \":\")\n",
    "\n",
    "    # remove dimensions of length=1\n",
    "    probs = np.squeeze(probs)\n",
    "\n",
    "    # sort then return top report_top_n entries\n",
    "    top_ind = np.argsort(probs)[-report_top_n:][::-1]\n",
    "    \n",
    "    # print out top probabilities, looking up label\n",
    "    print(\"Probability% is <label>\")\n",
    "    for id in top_ind:\n",
    "        det_label = labels_map[id] if labels_map else f\"#{id}\"\n",
    "        print(f\" {probs[id]*100:.7f} % is {det_label}\")\n",
    "    print(\"_______________________________________________________\")\n",
    "    \n",
    "    showImage(image_name,orig_input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4517dc",
   "metadata": {},
   "source": [
    "### 5.      inferImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferImage(image, input_path, image_name):\n",
    "    # prepare input\n",
    "    in_frame = resizeInputImage(image)\n",
    "\n",
    "    # run inference\n",
    "    res = exec_net.infer(inputs={input_blob: in_frame})\n",
    "\n",
    "    # process inference results\n",
    "    processAndDisplayResults(res[output_blob][0], image, input_path,image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a13095",
   "metadata": {},
   "source": [
    "### 6.      batchLoadInputImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0128db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to load input images into input batch\n",
    "def batchLoadInputImages(batch_paths):\n",
    "    global batch_size\n",
    "    global batch_images\n",
    "    global orig_image_paths\n",
    "    global orig_images\n",
    "    batch_size = len(batch_paths)\n",
    "\n",
    "    # create input batch (array) of input images\n",
    "    batch_images = np.ndarray(shape=(batch_size, c, h, w))\n",
    "\n",
    "    # create array to hold original images and paths for displaying later\n",
    "    orig_images = []\n",
    "    orig_image_paths = []\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # load image\n",
    "        image = loadInputImage(batch_paths[i])\n",
    "\n",
    "        # save original image and path\n",
    "        orig_images.append(image)\n",
    "        orig_image_paths.append(batch_paths[i])\n",
    "\n",
    "        # prepare input\n",
    "        in_frame = resizeInputImage(image)\n",
    "\n",
    "        # add input to batch\n",
    "        batch_images[i] = in_frame\n",
    "    return batch_size, batch_images, orig_image_paths, orig_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a6200a",
   "metadata": {},
   "source": [
    "### 7.      batchProcessAndDisplayResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a275285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to process inference results\n",
    "def batchProcessAndDisplayResults(result, orig_input_images, orig_image_paths, orig_image_name):\n",
    "    # get output results\n",
    "    res = result[output_blob]\n",
    "\n",
    "    for i, probs in enumerate(res):\n",
    "        processAndDisplayResults(probs, orig_input_images[i], orig_image_paths[i], orig_image_name[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5814cf",
   "metadata": {},
   "source": [
    "## C. Creating useful functions  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f8aa1",
   "metadata": {},
   "source": [
    "### I.     Getting the pre-traine model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5fb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "!downloader.py --name squeezenet1.1 -o raw_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7da193c",
   "metadata": {},
   "source": [
    "### II.    Using the Model Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150eed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!converter.py --name squeezenet1.1 -d raw_model -o model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb2570",
   "metadata": {},
   "source": [
    "### III.    Configuring OpenVINO parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model IR files\n",
    "model_xml = \"model/public/squeezenet1.1/FP32/squeezenet1.1.xml\"\n",
    "model_bin = \"model/public/squeezenet1.1/FP32/squeezenet1.1.bin\"\n",
    "\n",
    "# input image file\n",
    "input_path = \"./ai1_dogo.jpg\"\n",
    "\n",
    "# CPU extension library to use\n",
    "cpu_extension_path = (\n",
    "    os.path.expanduser(\"~\")\n",
    "    + \"/inference_engine_samples/intel64/Release/lib/libcpu_extension.so\"\n",
    ")\n",
    "\n",
    "# device to use\n",
    "device = \"CPU\"\n",
    "\n",
    "# number of top results to display\n",
    "report_top_n = 10\n",
    "\n",
    "# output labels\n",
    "labels_path = \"squeezenet1.1.labels\"\n",
    "\n",
    "print( \"Configuration parameters settings:\", \n",
    "       \"\\n\\tmodel_xml=\", model_xml,\n",
    "       \"\\n\\tmodel_bin=\", model_bin,\n",
    "       \"\\n\\tinput_path=\", input_path,\n",
    "       \"\\n\\tdevice=\", device,\n",
    "       \"\\n\\tlabels_path=\", labels_path,\n",
    "       \"\\n\\treport_top_n=\",report_top_n,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ca982",
   "metadata": {},
   "source": [
    "### IV.     Creating the inference engine instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102235fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Inference Engine instance\n",
    "ie = IECore()\n",
    "print(\"An Inference Engine object has been created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7629a",
   "metadata": {},
   "source": [
    "### V.     Creating the IENetwork & loading the model in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bdcd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network from IR files\n",
    "net = ie.read_network(model=model_xml, weights=model_bin)\n",
    "print(\"Loaded model IR files [\", model_bin, \"] and [\", model_xml, \"]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d293a",
   "metadata": {},
   "source": [
    "### VI.   Checking layer compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd848ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure that the plugin has support for all layers in the loaded model\n",
    "supported_layers = ie.query_network(net, device)\n",
    "not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]\n",
    "if len(not_supported_layers) != 0:\n",
    "    print(\"ERROR: Following layers are not supported by the plugin for specified\",\n",
    "          \" device {}:\\n {}\".format(device, \", \".join(not_supported_layers)),)\n",
    "    if 0 != 1:\n",
    "        raise Exception(\"ERROR: Missing support for all layers in the model, cannot continue.\")\n",
    "\n",
    "    # check to make sue that the model's input and output are what is expected\n",
    "    if len(net.inputs.keys()) != 1:\n",
    "        raise Exception(\"ERROR: This sample supports only single input topologies.\")\n",
    "    if len(net.outputs) != 1:\n",
    "        raise Exception(\"ERROR: This sample supports only single output topologies.\")\n",
    "print(\"SUCCESS: Model IR files have been loaded and verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b8e4d2",
   "metadata": {},
   "source": [
    "### VII. Loading the model into the plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250fb7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_net = ie.load_network(network=net, num_requests=2, device_name=device)\n",
    "\n",
    "# store name of input and output blobs\n",
    "input_blob = next(iter(net.inputs))\n",
    "output_blob = next(iter(net.outputs))\n",
    "\n",
    "# read the input's dimensions: n=batch size, c=number of channels, h=height, w=width\n",
    "n, c, h, w = net.inputs[input_blob].shape\n",
    "print(\"Loaded model into Inference Engine for device:\", device,\n",
    "      \"\\nModel input dimensions:\",\n",
    "      \" n=\",n,\n",
    "      \", c=\",c,\n",
    "      \", h=\",h,\n",
    "      \", w=\",w,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61861c0",
   "metadata": {},
   "source": [
    "### VIII.     Loading labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed42988",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = None\n",
    "# if labels points to a label mapping file, then load the file into labels_map\n",
    "print(labels_path)\n",
    "if os.path.isfile(labels_path):\n",
    "    with open(labels_path) as f:\n",
    "        labels_map = [x.split(sep=\" \", maxsplit=1)[-1].strip() for x in f]\n",
    "    print(\"Loaded label mapping file [\", labels_path, \"]\")\n",
    "else:\n",
    "    print(\"No label mapping file has been loaded, only numbers will be used\",\n",
    "          \" for detected object labels\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a72101",
   "metadata": {},
   "source": [
    "### IX.     Preparing the Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce85e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "image = loadInputImage(input_path)\n",
    "\n",
    "# resize the input image\n",
    "in_frame = resizeInputImage(image)\n",
    "\n",
    "# display input image\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "print(\"The AI dogo:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c3a74a",
   "metadata": {},
   "source": [
    "### X.     Running the Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387359c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save start time\n",
    "inf_start = time.time()\n",
    "\n",
    "# run inference\n",
    "res = exec_net.infer(inputs={input_blob: in_frame})\n",
    "# calculate time from start until now\n",
    "inf_time = time.time() - inf_start\n",
    "print(f\"Inference complete, run time: {inf_time * 1000:.3f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e53029",
   "metadata": {},
   "source": [
    "### XI.     Processing and Displaying Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca07487",
   "metadata": {},
   "outputs": [],
   "source": [
    "processAndDisplayResults(res[output_blob][0], image, input_path,\"AI dogo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178adac6",
   "metadata": {},
   "source": [
    "## D. Exercise explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a113219",
   "metadata": {},
   "source": [
    "### a. Loading a different image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e4c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to different input image\n",
    "input_path = \"ai1_cat.jpg\"\n",
    "\n",
    "# load input image\n",
    "image = loadInputImage(input_path)\n",
    "\n",
    "# infer image and display results\n",
    "inferImage(image, input_path,\"AI Cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561874c",
   "metadata": {},
   "source": [
    "### b. Loading an image from the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db746bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path may be set to a local file or URL\n",
    "input_path = \"https://upload.wikimedia.org/wikipedia/commons/5/56/Sea_Anemone_%2810062178943%29.jpg\"\n",
    "\n",
    "# load input image\n",
    "image = loadInputImage(input_path)\n",
    "\n",
    "# infer image and display results\n",
    "inferImage(image, input_path, \"Anemone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5cd6ee",
   "metadata": {},
   "source": [
    "### c. Loading multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch of inputs which may be local files or URLs (comma separated)\n",
    "batch_paths = [\"./ai2_dogo.jpg\", \"./ai1_cat.jpg\", \"./ai1_bird.jpg\"]\n",
    "batch_image_names = [\"AI Dogo 2\", \"AI Cat\", \"AI Bird\"]\n",
    "batchLoadInputImages(batch_paths)\n",
    "print(\"\\nLoaded\", batch_size, \"images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40141ea4",
   "metadata": {},
   "source": [
    "### d. Running multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d167694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the batch size to match the number of input images\n",
    "net.batch_size = batch_size\n",
    "print(\"Network batch size set to\", batch_size)\n",
    "\n",
    "## reload network because batch size has changed\n",
    "exec_net = ie.load_network(network=net, num_requests=2, device_name=device)\n",
    "\n",
    "\n",
    "# save start time\n",
    "inf_start = time.time()\n",
    "\n",
    "# run inference\n",
    "res = exec_net.infer(inputs={input_blob: batch_images})\n",
    "\n",
    "# calculate time from start until now\n",
    "inf_time = time.time() - inf_start\n",
    "print(f\"Inference complete, run time: {inf_time * 1000:.3f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cf899e",
   "metadata": {},
   "source": [
    "### e. Processing & displaying multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process inference results\n",
    "batchProcessAndDisplayResults(res, orig_images, orig_image_paths, batch_image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e6139c",
   "metadata": {},
   "source": [
    "# Exercise time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de42a7e0",
   "metadata": {},
   "source": [
    "## 01. Load and Process 10 AI generated images\n",
    "\n",
    "For your first task, you will use the already setted up model, and use to analyze 10 new images. You can use the internet or a generative AI website to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fba46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch of inputs which may be local files or URLs (comma separated)\n",
    "batch_paths = [ \"https://cdn.pixabay.com/photo/2015/06/25/12/27/daisy-821222_1280.jpg\", \"./cat.jpg\", ]\n",
    "\n",
    "# load batch of inputs\n",
    "batchLoadInputImages(batch_paths)\n",
    "print(\"Loaded\", batch_size, \"images.\")\n",
    "\n",
    "# set the batch size to match the number of input images\n",
    "net.batch_size = batch_size\n",
    "print(\"Network batch size set to\", batch_size)\n",
    "\n",
    "# reload network because batch size has changed\n",
    "exec_net = ie.load_network(network=net, num_requests=2, device_name=device)\n",
    "\n",
    "# run inference\n",
    "res = exec_net.infer(inputs={input_blob: batch_images})\n",
    "\n",
    "# process inference results\n",
    "batchProcessAndDisplayResults(res, orig_images, orig_image_paths)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52373d3",
   "metadata": {},
   "source": [
    "## 10. Change the display format\n",
    "\n",
    "Your second task is using a different way to display the results of the image analysis. You can modify some of the printed, or you can also use Matplotlib to display a graph of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61065456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAndDisplayResults(probs, orig_input_image, orig_input_path, image_name):\n",
    "    \n",
    "    # report top n results for image\n",
    "    print(\"Top \", report_top_n, \" results for image\", orig_input_path, \":\")\n",
    "\n",
    "    # remove dimensions of length=1\n",
    "    probs = np.squeeze(probs)\n",
    "\n",
    "    # sort then return top report_top_n entries\n",
    "    top_ind = np.argsort(probs)[-report_top_n:][::-1]\n",
    "    \n",
    "    # print out top probabilities, looking up label\n",
    "    print(\"Probability% is <label>\")\n",
    "    for id in top_ind:\n",
    "        det_label = labels_map[id] if labels_map else f\"#{id}\"\n",
    "        print(f\" {probs[id]*100:.7f} % is {det_label}\")\n",
    "    print(\"_______________________________________________________\")\n",
    "    \n",
    "    showImage(image_name,orig_input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your inputs - CODE GOES BELLOW \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3220bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the Inference - CODE GOES BELLOW \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and Display your results - CODE GOES BELLOW\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d07f34",
   "metadata": {},
   "source": [
    "## 11. Change the following\n",
    "The last task is modifying our previous setup. You'll need to:\"\\n\"\n",
    "\n",
    "1. Change the number of posible things in the analysis\n",
    "2. Change the device used to compute the model\n",
    "3. Change the model from 1.1 to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69cf01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go Nuts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
